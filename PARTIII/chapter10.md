# 第十章 批量处理

三种类型系统：
- 服务(在线系统):向数据库发送请求或者命令，然后期望得到回应。我们主要关注系统的相应时间和可用性。
- 批量处理(离线计算):一次读取大量数据，然后处理它们，一般都是定时任务，主要关注点是吞吐量。
- 流式处(近乎实时计算):介于前两者之间，基于事件消费输入，产生输出。

批量处理是系统的重要部分，比如`MapReduce`，一种底层程序模型。

## 用Unix工具批处理
一段nginx日志。

### 简单的日志分析
一条bash命令
```bash
cat file |  # 读取日志文件
    awk '{print $7}' | # 取出第七个空白分割的单词
    sort | # 排序
    uniq -c | # 去重而且计数
    sort -r -n | # 排序倒叙按照计数
    head -n 5 | # 显示前五
```
#### 命令链对比定制程序

一段ruby程序效果等同上文。

#### 排序对比内存聚合
两种方法都不错，不过内存内聚合只能用到内存空间，而`Unix sort`可以用硬盘对付大量数据。

### Unix的哲学
Unix能对付这么大的数据并非偶然，而是设计如此，Unix系统的哲学：
1. 每个程序可以完成一件事。不要在老方法增加特性实现新功能。
2. 每个程序的输入都是其他程序的输出。
3. 早点尝试，不要犹豫，不要害怕丢掉错误的部分和重构。
4. 使用工具让任务轻量化，尽管你可能为了制造工具要走弯路，甚至可能在后来将他们抛弃。

这套方法可以将复杂任务分解，就像敏捷开发以及DevOps一样。Unix的Shell可以让我们组合这些简单的工具完成数据处理工作。

#### 一致的接口
为了让一个程序的输出变成另一个程序的输入，最简单的方法就是保持一个一致的接口，比如`Unix`中就是用文件或者一串比特完成的。

#### 逻辑和接线的分离
`Unix`将输入输出接线和程序逻辑分离。可以使得程序的复用性大大提高。不过对于多输入多输出可能会减弱程序的灵活性。

#### 透明和实现性
Unix命令的几个大优势。
1. 输入不会改变。不用担心实验性代码毁坏原始数据。
2. 可以在任何地方停下来用`less`查看中间状态并`debug`。
3. 中间结果可以保存在文件中，这样可以分部处理。

不过它有一个致命弱点，只能运行在单机上。

## MapReduce
`MapReduce`就像是在分布式系统的`Unix Tool`每个任务就相当于一次`Unix`进程和`Unix Tool`一样，不会改变任何输出。它的输入输出都是标准`HDFS`文件。`HDFS`采用不共享原则（NAS是共享硬盘)，不需要任何特殊硬件。`HDFS`可以使用每台机器上的任何磁盘，将文件存储备份，和`RAID`不同不需要任何额外硬件，只依赖网络。

### MapReduce 任务执行
以上面例子为例。Map对应这个过程:
```bash
awk '{print $7}' 
```
Reduce对应这个过程:
```bash
uniq -c
```
其他过程比如:
```bash
cat file |  # 读取日志文件
```
是由文件解析器提供。
```bash
sort
```
则是由系统自动完成

为了实现一个`MapReduce`任务我们需要提供一个`Mapper`方程和一个`Reducer`方程。

#### MapReduce 的分布式执行
MapReduce和`Unix`工具的一个很大不同在于它可以分布式执行，而不需要做任何的并行修改。MapReduce对每部分数据启动一个单独的Mapper。Hadoop采取就近计算原则，会让数据计算发生在数据存储的机器上，减少网络开销。`Jar`包被发送到执行机器上，让`Mapper`处理，处理完的结果会存储在HDFS上并排序，之后按照HaskKey来确定执行`Reduce`任务机器的。`Reducer`获取`Mapper`结果的过程叫`Shuffle`。

#### MapReduce 工作流
单个`MapReduce`能完成的功能很有限，所以经常要串起来形成工作流。不过`Hadoop MapReuce`没有对工作流优化，所有内容必须自己写。而且一个工作必须等上一个工作完成才能开始。为了管理这些工作流，人们开发了很多工具。

### Reduce任务中的join和group操作。


## 超越MapReduce

## 总结
