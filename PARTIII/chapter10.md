# 第十章 批量处理

三种类型系统：
- 服务(在线系统):向数据库发送请求或者命令，然后期望得到回应。我们主要关注系统的相应时间和可用性。
- 批量处理(离线计算):一次读取大量数据，然后处理它们，一般都是定时任务，主要关注点是吞吐量。
- 流式处(近乎实时计算):介于前两者之间，基于事件消费输入，产生输出。

批量处理是系统的重要部分，比如`MapReduce`，一种底层程序模型。

## 用Unix工具批处理
一段nginx日志。

### 简单的日志分析
一条bash命令
```bash
cat file |  # 读取日志文件
    awk '{print $7}' | # 取出第七个空白分割的单词
    sort | # 排序
    uniq -c | # 去重而且计数
    sort -r -n | # 排序倒叙按照计数
    head -n 5 | # 显示前五
```
#### 命令链对比定制程序

一段ruby程序效果等同上文。

#### 排序对比内存聚合
两种方法都不错，不过内存内聚合只能用到内存空间，而`Unix sort`可以用硬盘对付大量数据。

### Unix的哲学
Unix能对付这么大的数据并非偶然，而是设计如此，Unix系统的哲学：
1. 每个程序可以完成一件事。不要在老方法增加特性实现新功能。
2. 每个程序的输入都是其他程序的输出。
3. 早点尝试，不要犹豫，不要害怕丢掉错误的部分和重构。
4. 使用工具让任务轻量化，尽管你可能为了制造工具要走弯路，甚至可能在后来将他们抛弃。

这套方法可以将复杂任务分解，就像敏捷开发以及DevOps一样。Unix的Shell可以让我们组合这些简单的工具完成数据处理工作。

#### 一致的接口
为了让一个程序的输出变成另一个程序的输入，最简单的方法就是保持一个一致的接口，比如`Unix`中就是用文件或者一串比特完成的。

#### 逻辑和接线的分离
`Unix`将输入输出接线和程序逻辑分离。可以使得程序的复用性大大提高。不过对于多输入多输出可能会减弱程序的灵活性。

#### 透明和实现性
Unix命令的几个大优势。
1. 输入不会改变。不用担心实验性代码毁坏原始数据。
2. 可以在任何地方停下来用`less`查看中间状态并`debug`。
3. 中间结果可以保存在文件中，这样可以分部处理。

不过它有一个致命弱点，只能运行在单机上。

## MapReduce
`MapReduce`就像是在分布式系统的`Unix Tool`每个任务就相当于一次`Unix`进程和`Unix Tool`一样，不会改变任何输出。它的输入输出都是标准`HDFS`文件。`HDFS`采用不共享原则（NAS是共享硬盘)，不需要任何特殊硬件。`HDFS`可以使用每台机器上的任何磁盘，将文件存储备份，和`RAID`不同不需要任何额外硬件，只依赖网络。

### MapReduce 任务执行
以上面例子为例。Map对应这个过程:
```bash
awk '{print $7}' 
```
Reduce对应这个过程:
```bash
uniq -c
```
其他过程比如:
```bash
cat file |  # 读取日志文件
```
是由文件解析器提供。
```bash
sort
```
则是由系统自动完成

为了实现一个`MapReduce`任务我们需要提供一个`Mapper`方程和一个`Reducer`方程。

#### MapReduce 的分布式执行
MapReduce和`Unix`工具的一个很大不同在于它可以分布式执行，而不需要做任何的并行修改。MapReduce对每部分数据启动一个单独的Mapper。Hadoop采取就近计算原则，会让数据计算发生在数据存储的机器上，减少网络开销。`Jar`包被发送到执行机器上，让`Mapper`处理，处理完的结果会存储在HDFS上并排序，之后按照HaskKey来确定执行`Reduce`任务机器的。`Reducer`获取`Mapper`结果的过程叫`Shuffle`。

#### MapReduce 工作流
单个`MapReduce`能完成的功能很有限，所以经常要串起来形成工作流。不过`Hadoop MapReuce`没有对工作流优化，所有内容必须自己写。而且一个工作必须等上一个工作完成才能开始。为了管理这些工作流，人们开发了很多工具。

### Reduce任务中的join和group操作。
MapReduce数据没有索引。Reduce中的join操作都是涉及分析聚合任务，所以会读取全部数据，而不像Relation DB中只是为了寻找单一用户。

#### 案例：分析用户行为。
为了提高吞吐量不会对数据逐条分析。而是使用用ETL进程一次读取全部数据库数据，然后一次处理他们。

#### 排序合并 join
两种不同的map任务将相同的用户id作为key，排序合并。这样在reduce阶段，同一个key需要聚合的数据就会到一起处理。而每次reduce任务，只用一个用户的数据，所以内存需求不会太大。

#### 将关联数据放到一起
在一次排序合并join中，排序操作会将所需聚合的数据弄到一起。然后reduce操作就会变得简单。MapReduce将网络传输和业务逻辑隔离开来，节点错误等问题也会自动得到处理。

### Group By
除了join另一个reduce阶段常用功能就是`Group By`，将需要`Group By`的字段设为`Map Key`然后就能进行各种聚合操作。其中还有一个很重要工作是让每个key的内容形成一串序列，然后在此之上进行各种分析。

#### 处理偏斜
有时候单一`key`相比其他会有相当多的内容。比如大V的关注列表。这些`key`叫`hot key`。有多种算法处理这个问题，比如手动设定`hot key`或者先跑个采样数据并对`key`的数量进行排序。

### Map侧的join操作
Map侧的join操作有个问题，需要排序，需要reducer。而简单join可以仅仅只用`mapper`就完成。
#### 广播hash join
如果大数据集join小数据集，最简单方法是将整个小数据集读入内存，然后用广播hash方法依次处理每一个mapper。这个方法被Hive, Pig等支持。

#### hash join 分区
如果原始数据已经通过hash分区，则join的小数据集可以只读入分区中包含的key的内容。

#### Map侧的merge-join
如果原始数据已经排好序，这样map可以做到reduce可以做的工作。

#### Map侧join的MapReduce工作流
reduce join可以让主键重新排列，而map则不会改变主键每个文件中的主键保持不变。

### 批处理工作流的输出
和OLTP主要按`key`取数据展示给用户不同OLAP任务主要生成报告。而MapReduce任务又更不同，它甚至不生成报告，而是生成某种结构数据。

#### 建立搜索引擎索引
可以用来做倒排索引

#### KV存储
类似之前做过的bulk loading。

#### 批处理结果的哲学
与UNIX很相似但是UNIX只能处理无类型txt文件，HADOOP则能读取某些格式化数据文件。HADOOP很容易重跑，对原始文件不会构成影响，如果某次任务失败会自动重启，同一个原始数据可以用作不同用途。

### 将Hadoop和分布式数据库对比
在HADOOP之前很多并行算法就已经被发明出来，还有很多大数据数据库存在，不过它们之间还是有很多不同，大数据数据库更多关注于在一个集群上运行SQL。而HADOOP 更类似于一个分布式的通用操作系统。

#### 存储的分别
Hadoop是将数据处理任务交给消费者，而关系数据库则是数据生产者。消费者处理更有利于跨部门合作，而且可以更方便多个消费者不用的应用场景。Hadoop更类似数据仓库用在各种ETL任务中。

#### 处理模型的分别
关系数据库适合增删改查，对SQL语句专门优化，使用范围受到限制，不适合机器学习，全文索引，推荐系统等方面。而Hadoop则更为通用，通过编写程序提供更大的灵活度，(不过其也在某些任务上表现不佳) 

#### 容错设计
MapReduce对错误不敏感，有节点失败会自动重启，自动重跑上面的任务。而关系数据库则会直接退出整个查询。

## 超越MapReduce

## 总结
