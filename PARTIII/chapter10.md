# 第十章 批量处理

三种类型系统：
- 服务(在线系统):向数据库发送请求或者命令，然后期望得到回应。我们主要关注系统的相应时间和可用性。
- 批量处理(离线计算):一次读取大量数据，然后处理它们，一般都是定时任务，主要关注点是吞吐量。
- 流式处(近乎实时计算):介于前两者之间，基于事件消费输入，产生输出。

批量处理是系统的重要部分，比如`MapReduce`，一种底层程序模型。

## 用Unix工具批处理
一段nginx日志。

### 简单的日志分析
一条bash命令
```bash
cat file |  # 读取日志文件
    awk '{print $7}' | # 取出第七个空白分割的单词
    sort | # 排序
    uniq -c | # 去重而且计数
    sort -r -n | # 排序倒叙按照计数
    head -n 5 | # 显示前五
```
#### 命令链对比定制程序

一段ruby程序效果等同上文。

#### 排序对比内存聚合
两种方法都不错，不过内存内聚合只能用到内存空间，而`Unix sort`可以用硬盘对付大量数据。

### Unix的哲学
Unix能对付这么大的数据并非偶然，而是设计如此，Unix系统的哲学：
1. 每个程序可以完成一件事。不要在老方法增加特性实现新功能。
2. 每个程序的输入都是其他程序的输出。
3. 早点尝试，不要犹豫，不要害怕丢掉错误的部分和重构。
4. 使用工具让任务轻量化，尽管你可能为了制造工具要走弯路，甚至可能在后来将他们抛弃。

这套方法可以将复杂任务分解，就像敏捷开发以及DevOps一样。Unix的Shell可以让我们组合这些简单的工具完成数据处理工作。

#### 一致的接口
为了让一个程序的输出变成另一个程序的输入，最简单的方法就是保持一个一致的接口，比如`Unix`中就是用文件或者一串比特完成的。

#### 逻辑和接线的分离
`Unix`将输入输出接线和程序逻辑分离。可以使得程序的复用性大大提高。不过对于多输入多输出可能会减弱程序的灵活性。

#### 透明和实现性
Unix命令的几个大优势。
1. 输入不会改变。不用担心实验性代码毁坏原始数据。
2. 可以在任何地方停下来用`less`查看中间状态并`debug`。
3. 中间结果可以保存在文件中，这样可以分部处理。

不过它有一个致命弱点，只能运行在单机上。

## MapReduce
`MapReduce`就像是在分布式系统的`Unix Tool`每个任务就相当于一次`Unix`进程和`Unix Tool`一样，不会改变任何输出。它的输入输出都是标准`HDFS`文件。`HDFS`采用不共享原则（NAS是共享硬盘)，不需要任何特殊硬件。`HDFS`可以使用每台机器上的任何磁盘，将文件存储备份，和`RAID`不同不需要任何额外硬件，只依赖网络。

### MapReduce 任务执行
以上面例子为例。Map对应这个过程:
```bash
awk '{print $7}' 
```
Reduce对应这个过程:
```bash
uniq -c
```
其他过程比如:
```bash
cat file |  # 读取日志文件
```
是由文件解析器提供。
```bash
sort
```
则是由系统自动完成

为了实现一个`MapReduce`任务我们需要提供一个`Mapper`方程和一个`Reducer`方程。

#### MapReduce 的分布式执行
MapReduce和`Unix`工具的一个很大不同在于它可以分布式执行，而不需要做任何的并行修改。MapReduce对每部分数据启动一个单独的Mapper。Hadoop采取就近计算原则，会让数据计算发生在数据存储的机器上，减少网络开销。`Jar`包被发送到执行机器上，让`Mapper`处理，处理完的结果会存储在HDFS上并排序，之后按照HaskKey来确定执行`Reduce`任务机器的。`Reducer`获取`Mapper`结果的过程叫`Shuffle`。

#### MapReduce 工作流
单个`MapReduce`能完成的功能很有限，所以经常要串起来形成工作流。不过`Hadoop MapReuce`没有对工作流优化，所有内容必须自己写。而且一个工作必须等上一个工作完成才能开始。为了管理这些工作流，人们开发了很多工具。

### Reduce任务中的join和group操作。
MapReduce数据没有索引。Reduce中的join操作都是涉及分析聚合任务，所以会读取全部数据，而不像Relation DB中只是为了寻找单一用户。

#### 案例：分析用户行为。
为了提高吞吐量不会对数据逐条分析。而是使用用ETL进程一次读取全部数据库数据，然后一次处理他们。

#### 排序合并 join
两种不同的map任务将相同的用户id作为key，排序合并。这样在reduce阶段，同一个key需要聚合的数据就会到一起处理。而每次reduce任务，只用一个用户的数据，所以内存需求不会太大。

#### 将关联数据放到一起
在一次排序合并join中，排序操作会将所需聚合的数据弄到一起。然后reduce操作就会变得简单。MapReduce将网络传输和业务逻辑隔离开来，节点错误等问题也会自动得到处理。

### Group By
除了join另一个reduce阶段常用功能就是`Group By`，将需要`Group By`的字段设为`Map Key`然后就能进行各种聚合操作。其中还有一个很重要工作是让每个key的内容形成一串序列，然后在此之上进行各种分析。

#### 处理偏斜
有时候单一`key`相比其他会有相当多的内容。比如大V的关注列表。这些`key`叫`hot key`。有多种算法处理这个问题，比如手动设定`hot key`或者先跑个采样数据并对`key`的数量进行排序。

### Map侧的join操作
Map侧的join操作有个问题，需要排序，需要reducer。而简单join可以仅仅只用`mapper`就完成。
#### 广播hash join
如果大数据集join小数据集，最简单方法是将整个小数据集读入内存，然后用广播hash方法依次处理每一个mapper。这个方法被Hive, Pig等支持。

#### hash join 分区
如果原始数据已经通过hash分区，则join的小数据集可以只读入分区中包含的key的内容。

#### Map侧的merge-join
如果原始数据已经排好序，这样map可以做到reduce可以做的工作。

#### Map侧join的MapReduce工作流
reduce join可以让主键重新排列，而map则不会改变主键每个文件中的主键保持不变。

### 批处理工作流的输出
和OLTP主要按`key`取数据展示给用户不同OLAP任务主要生成报告。而MapReduce任务又更不同，它甚至不生成报告，而是生成某种结构数据。

#### 建立搜索引擎索引
可以用来做倒排索引

#### KV存储
类似之前做过的bulk loading。

#### 批处理结果的哲学
与UNIX很相似但是UNIX只能处理无类型txt文件，HADOOP则能读取某些格式化数据文件。HADOOP很容易重跑，对原始文件不会构成影响，如果某次任务失败会自动重启，同一个原始数据可以用作不同用途。

### 将Hadoop和分布式数据库对比
在HADOOP之前很多并行算法就已经被发明出来，还有很多大数据数据库存在，不过它们之间还是有很多不同，大数据数据库更多关注于在一个集群上运行SQL。而HADOOP 更类似于一个分布式的通用操作系统。

#### 存储的分别
Hadoop是将数据处理任务交给消费者，而关系数据库则是数据生产者。消费者处理更有利于跨部门合作，而且可以更方便多个消费者不用的应用场景。Hadoop更类似数据仓库用在各种ETL任务中。

#### 处理模型的分别
关系数据库适合增删改查，对SQL语句专门优化，使用范围受到限制，不适合机器学习，全文索引，推荐系统等方面。而Hadoop则更为通用，通过编写程序提供更大的灵活度，(不过其也在某些任务上表现不佳) 

#### 容错设计
MapReduce对错误不敏感，有节点失败会自动重启，自动重跑上面的任务。而关系数据库则会直接退出整个查询。

## 超越MapReduce
MapReduce只是诸多分布式计算模型中的一种，而且写起来比较麻烦。在其之上有`Pig`,`Hive`等基于它的上层应用。不过它在处理某些问题的时候会比较慢。

### 中间状态物料化
一个MapReduce工作流中有很多中间结果。将这些中间结果写到分布式文件系统的操作叫物料化。物料化有以下问题。
1. 只有前一个MapReduce任务完成，中间结果全部生成，下一个任务才会开始。
2. Mapper读中间结果和Reduce写中间结果的过程有冗余计算过程。
3. 中间结果也会多倍备份，这对临时数据是不必要的。

#### 数据流引擎
为了解决这些问题，有几种常见的引擎:`Spark`,`Tez`,`Flink`。它们的实现有所不同，但是有一个共同点：将整个工作流当做一个任务，而不是将其分解为一个个子任务。所以它们又叫数据流引擎。和MapReduce不同，它们的是由`Operator`组合而成的。为了将Operator管道连接，有几种中间操作：
1. 按key排序，重新分区。这个可以实现排序合并join，还有group by
2. 另一种方法是将多种输入hash分区，但是不排序，这个适合Hash join操作。
3. 广播hash join，将大数据集直接用包含小数据集的`Operator`join处理。

这个方法有很多优势：
1. 不在需要不必要的shuffle。
2. 不再需要不必要的map操作。
3. 某些数据可以一直在同一台机器处理不再需要数据交换。
4. 数据一致在内存中，节约了不必要的I/O写硬盘时间。
5. 输入准备好下个操作就可以开始，不用等整个MapReduce任务完成。
6. 减少了不必要的JVM启动时间。

#### 容错
中间物料没有保存，所以数据流引擎如果出现错误，需要向前追溯甚至需要从头开始计算。为了追溯数据源头，这些引擎保存了完整的数据计算轨迹图。不过一些非确定性的计算（结果不仅仅依赖初始值）流程可能会让问题更为复杂化。所以要尽量避免使用非确定性计算。

#### 讨论物料化
数据流引擎为了减少重复计算也会经常使用持久化操作。

### 图和迭代操作
计算机图的迭代算法是批处理中一个重要组成部分，比如PageRank。这种算法会涉及一个迭代过程。这个流程使用MapReduce会颇为浪费，因为每次迭代都要读写全部数据。

#### Pregel 处理模型
在处理图模型的优化中，`bulk synchronous parallel (BSP)`模型开始流行起来。使用它的应用有`Spark`的`GraphX`。`FLink`的`Gelly`。主要实现在谷歌的`Pregel`论文中提到。[论文]()

信息沿着边传递。然后，没有新变化的地方不会重复计算。

#### 容错
因为信息传递互不影响，所以同一次迭代中，信息传递可以并行化处理。但是不同次迭代必须等前一次结束后一次才能开始。每经过几次迭代数据就会自动持久化存储。

#### 并行执行
顶点通过边传递信息时并不需要知道对面顶点所在机器，所以这个模型下会有大量的网络调用。所以单机图计算通常会比多机效率高很多，如果提高多机图计算效率依然是个前沿话题。

### 高级API和语言
现在Hadoop基础设施已经足够健壮，所以目前的热点在于优化编程程序模型，效率，和适用范围。在Hadoop之上有很多高级API方便适用，他们还提供诸如交互式数据探索之类的功能。

#### 向申明式查询迁移
申明式查询可以帮助我们减少了解多种不同join的细节，自动选择合适的join方式。还有一些filter操作放到内循环能大大减少cpu负载，这些优化在很多数据中已经实现。但是所有这以前它会像之前讨论的MPP那样大大减少系统的灵活性。不过总的来说现在分布式批处理任务越来越像MPP，同时还继续保持着自己的灵活性。

#### 不同领域的专门优化
还有很多领域比如机器学习会在分布式系统或者分布式数据库上专门优化。总的来说两者现在越来越相似了，毕竟它们的基本功能都是存储和处理数据。
## 总结
