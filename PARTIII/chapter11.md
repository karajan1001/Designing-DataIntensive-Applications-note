# 第十一章 流式计算

上一章批量处理中所有数据都是有界的。一个方法是将数据分成`chunk`但是这样处理结果会有延迟。对于一些实时性要求更高的工作，可以将其当做数据流处理。

## 传递事件流
流式计算的输入是一个个，小的自洽的不可变的事件。批量计算中，数据被写入到一个文件，然后被多个计算任务读取。而流式计算中，事件被一个生产者`producer`生产，然后被多个消费者`consumer`消费。批量处理中的消费者需要主动拉取数据，这样命中率很低，流式计算生产者主动推送数据，这样可以减少为了低延迟而进行的高频无效查询次数。关系型数据库对于这种推送方式支持不好，这是引入流式计算专门工具的一个重要原因。

### 消息系统
普通的Unix系统消息支持单对单，或者多对单的消息发送。不过一个消息系统支持，多个生产者将消息发送到同一个topic然后由多个消费者消费这个topic中的消息。一个消息系统要关注两个问题：

1. 如果消费者消费速度跟不上生产者生产速度会怎么样。特别是当缓存逐渐增长直到占满整个内存。消息是否会丢失。(三种措施: 丢弃，缓存，限流)
2. 如果系统崩溃，未发送的消息是否会丢失。

#### 信息在生产者和消费者之间的直接传递
很多消息系统直接在生产者和消费者之间传递消息。有低延迟的UDP，无broker的ZeroMQ，收集所有机器的UDP的statsD和Brubeck。还有消费者直接暴露HTTP，RPC协议。这些直接模式有个缺点，如果网络存在问题，消息可能会丢失。

#### 消息broker
又叫消息队列，是用来处理信息流的数据库。它可以将所有消息丢失问题集中到自己处处理。这样带来另一个异步处理的特性，生产者只要将消息给broker就可以去干其他事情。

#### 消息队列和数据库对比

- 消息队列中数据不会长期保留。
- 队列大小不会太大。
- 队列使用主题匹配方式，数据库采用索引匹配。
- 消息队列不能查询，但是会通知消费者数据变化。

#### 多消费者
有两种常用逻辑

- 负载均衡
- fan-out(广播类似)

#### 重新发送
因为消费者可能会出现错误，所以消费者必须返回broker消息处理成功与否。如果超时broker需要重新发送请求。不过因为回执也可能丢失，所以也许实际上消费者已经成功处理了请求。更常见的问题是重新发送的消息在队列中的顺序会出现错乱。

### 分布日志
消息队列和数据库还有文件系统一个很大不同是不会存历史数据，如果出现错误无法恢复重跑。

#### 用日志保存消息
一个可行的解决方案是使用文件日志保存消息数据，Kafka,Kinesis Stream, DistributedLog都是这样的解决方案。而且他们写文件系统使用分布式写的方式（同一分区内部时间顺序可以比较, 不同分区无法比较)。这些系统可以支持百万条消息每秒的吞吐量。

#### 基于log的消息队列和传统消息队列比较
这种消息队列会把一整块数据都给consumer,不过里面会记录上consumer需要处理的条目达到负载均衡。这种方式如果遇到某条消息处理时间较长，可能后面所有消息都会被堵塞，所以对于处理缓慢任务最好使用传统方式，一条一条发送消息，而如果需要大吞吐量，对顺序比较在意则可以使用一整块一起发送的方式。

#### 消费者offset
这个系统中，消息队列类似一个leader,而消费者类似一个worker。leader需要记录消费者消费的offset.之前的全部处理过，之后的全部没有处理。

#### 硬盘使用

#### 如果消费者跟不上生产者的进度
在日志消息队列中，人们有充分时间在发生报警后处理问题。

#### 重新计算老消息
而且历史数据也可以冲盘，这是相对传统消息队列的一个大优势。

## 数据库和流

### 保持系统同步
为了保持系统同步，一个方法是定时读取，然后批处理ETL写入。但是有时候这样做延迟会比较高，此时可以考虑使用双重写入`duel write`。不过这样做可能导致一些严重问题，
1. 顺序是
> A写1</br>
> B写1</br>
> B写2</br>
> A写2</br>

这样1是A，2是B两个数据库的数据发生不同步。

2. A写1成功写2失败，非原子提交。需要用2相提交(2PC)解决。

### 数据变化捕捉
之前很多数据库缺少日志记录文档，很难通过日志备份同步它们中的数据。不过最近数据变化捕捉慢慢成为了一个热门方向。

#### 应用数据变化捕捉
日志的消费者被称为"导出数据系统",数据变化捕捉的主要目标就是保证数据库的所有变化同样作用到这些导出数据系统中。

#### 初始快照
保存全部历史数据受到硬盘限制而成为不可能，旧的历史数据必然会被截断丢弃，此时为了可以让系统可以恢复，需要建立初始快照，初始快照前的日志都可以丢弃。

#### 日志压缩
和数据库中类似，引擎搜索数据中重复key合并之。

#### 数据流变化API

各种数据库都开始支持数据变化API。

### 事件源
事件源是DDD(领域驱动设计)中的一个概念，不过它和流系统中的一些有用的关点有诸多联系。与数据变化捕捉相比：
1. 数据变化捕捉是在从数据库底层日志中实现，这样保证前后关系一致。应用层感知不到CDC（数据变化捕捉）的存在。数据主要被记录在可变的数据库中，CDC只是数据库底层中抽出的一个应用。
2. 在事件源中，日志通过增量操作拼接到事件日志中。事件本身就反应应用层中内容，应用层直接和事件交互。事件本身就被记录在不可变的日志流中。

#### 从事件流中导出当前状态

一个事件日志流并不是很有用，因为我们更多希望看到的是系统的当前状态。所以我们需要一个转换操作将数据流转换成用户希望看到的状态，并且这是一个确定性的状态，同样的数据流数据永远只会得到一个既定结果。在数据库CDC中，一条更新操作，包含这个key全量的信息。只要有了这条更新的数据，之前所有的日志流都可以抛弃。而在事件流中，事件更多表示了用户的行为的依图。而不是当前的状态，想要得到当前状态必须从头开始，解析全部历史。虽然我们可以通过更新初始快照的方式加速这一过程，但是依然无法和记录状态的数据库相提并论，因为事件流系统的目标是记录所有原始事件，还有可以在需要的时候处理它们。

#### 命令和事件

事件和命令的区别在于。命令不一定成功，消费者可以拒绝执行命令，而事件则是无法改变的一个既定事实，就算这个事件后面被其他事件替代或者取消，消费者也需要将其执行完毕。


### 状态，流和不变性
