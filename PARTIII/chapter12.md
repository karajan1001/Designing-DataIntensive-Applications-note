# 第十二章 数据系统的未来
对未来的所有看法当然都是主观的，所以本章的内容只是作者的意思。本书的目标在第一张就已经说明：探索如何构建一个可靠可扩展可维护的系统。

## 数据集成
对于简单的有一组数据希望之后读取的问题，是没有正确答案的，不同的方案对应不同的情况

### combining specialized tools by deriving data

开发者经常会想当然对方想要它不想要它。

#### 数据流的原因
当数据的多份拷贝被存储在不同的数据库中，需要明确它们之间的依赖关系。

#### 数据导入核分布式事物的对比
分布式事物提供了线性一致性，可以保证读到写入的内容。不过分布式事物在容错和性能方面相当薄弱。

#### 完全顺序的局限性
完全顺序性的巨大缺点在于依赖单节点的处理能力。因为顺序要依赖单节点来确定。

### 批处理和流式处理
两者最本质区别在于一个是有界的另一个则是无界的。

#### 保持导出状态

#### 重复计算数据对应用演化的帮助
可以重复计算的历史数据可以帮助我们构建一个全新的数据视图

#### lambda 架构
将批量和流式系统组合起来，流式计算可以用快速的近似算法而批处理数据则可以用更多的容错核更复杂的计算。不过这个架构有几个缺点：
1. 维护多套计算引擎的维护成本。
2. 多套数据需要互相导入。
3. 重跑全量数据需要大量的计算成本。

#### 统一批处理和流式处理

## 非绑定数据流
最高抽象层级下，数据库，Hadoop和操作系统都在做同样的事，存储数据然后对它们操作。Unix更多针对硬件底层，数据库更多针对应用。

### 组合数据存储技术
#### 创建索引
创建一个新的索引的过程很类似创建一个新的备份，然后使用`数据变化捕捉(CDC)`。

#### 万物的元数据库
所有的ETL,batch,stream 数据流，可以被看成是一个'大的'数据库的索引工作。没有一种数据库可以满足我们所有的需求，但是我们可以把两种工具组成一个复合系统。`federated database`和`unbundled database`一个读统一,一个写统一。

#### 让非绑定数据流工作
传统的分布式事物在灵活性上要比事件日志导出的数据弱的多。而且我们可以只对特定消费者行为做顺序排列, 这样会大大减少系统复杂度。

#### 非绑定和集成系统
就算非绑定系统代表未来，他们也不会替代集成数据库，相反会更加依赖它们。非绑定系统会导致学习成本的大大增加，但是它可以可以比传统数据库适应更广的需求。非绑定数据流只在没有一款数据库能满足你全部需求时才应该使用。

#### 什么丢失了
目前我们没有一个可以让数据在不同数据库中统一流动的管道，就如同unix pipe 一样。(数据库可以看成 unix 中的 byte string) 

### 设计围绕非绑定数据库的应用
#### 应用代码作为导入函数
当一个数据集导入另一个数据集时一般都需要一些转化程序比如**第二索引构建**,**全文搜索引擎索引构建**,**机器学习依赖的数据预处理**,**统计的缓存系统**。让数据库执行任意转换代码通常会变得比较困难。

#### 将应用代码与状态独立
讲应用代码与状态独立出来的技术通常会取得比使用数据库自带的UDF更加好的效果。将无状态的代码与有状态的代码分离通常可以获得良好的效果。

#### 数据流:状态改变和应用代码的相互影响
我们可以让状态改变作为应用代码产生数据流的开关。容错是数据流的重要一环，稳定的消息发送与容错是刚性需要，现代流处理可以很好的保持数据流的顺序与可靠性。

#### 流处理与流服务
目前的趋势是将应用开发分解为微服务通过同步网络请求进行。这样的好处是可以让 不同团队不同应用解耦。有效的降低相互之间的交互。将流处理组合成数据流系统与微服务有很多相似之处，不过他们之下的通信方式有本质不同一个同步一个异步。流处理不光可以更好的容错也能提高性能。


#### 
